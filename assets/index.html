<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Regression Models Handbook — Index</title>
<link rel="stylesheet" href="styles.css" />
</head>
<body>
<main class="book-page">
  <header class="book-header">
    <p class="lead">Regression Models Handbook</p>
    <h1>Index</h1>
    <p class="muted">A concise, uniform blog-book of 18 regression models with background, math, code (expandable), and figures.</p>
  </header>

  <section class="table-of-contents">
    <ol>
      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-01.html">1. Linear Regression</a>
          <p><strong>What:</strong> Linear relationship for a continuous target; least squares estimator.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-02.html">2. Multiple Linear Regression</a>
          <p><strong>What:</strong> OLS with multiple predictors to estimate partial effects and control confounders.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-03.html">3. Lasso Regression (L1)</a>
          <p><strong>What:</strong> Adds an L1 penalty to induce sparsity (embedded feature selection).</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-04.html">4. Cox Proportional Hazards</a>
          <p><strong>What:</strong> Semiparametric survival model using partial likelihood; proportional hazards assumption.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-05.html">5. Ridge Regression (L2)</a>
          <p><strong>What:</strong> L2 penalty shrinks coefficients and stabilizes estimates under multicollinearity.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-06.html">6. Stepwise Regression</a>
          <p><strong>What:</strong> Greedy add/drop variable selection using AIC/BIC; quick but can be unstable.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-07.html">7. Logistic Regression (Binary)</a>
          <p><strong>What:</strong> Binary outcome via log-odds (logit) link; parameters via MLE.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-08.html">8. Elastic Net (L1+L2)</a>
          <p><strong>What:</strong> Blends L1 & L2 to select groups and shrink coefficients; good with collinearity.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-09.html">9. Polynomial Regression</a>
          <p><strong>What:</strong> Polynomial basis expansion; still linear in parameters; captures smooth curvature.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-10.html">10. Quantile Regression</a>
          <p><strong>What:</strong> Models conditional quantiles using pinball loss; robust to heteroskedasticity.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-11.html">11. Decision Tree Regression</a>
          <p><strong>What:</strong> CART splits minimize SSE; interpretable, piecewise-constant predictions.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-12.html">12. Random Forest Regression</a>
          <p><strong>What:</strong> Bagged trees with feature subsampling; robust baseline, reduced variance.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-13.html">13. Gradient Boosting Regression</a>
          <p><strong>What:</strong> Stagewise additive modeling on residuals/gradients; powerful for tabular data.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-14.html">14. Support Vector Regression (SVR)</a>
          <p><strong>What:</strong> ε-insensitive loss with kernels for nonlinearity; robust in high dimensions.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-15.html">15. XGBoost Regression</a>
          <p><strong>What:</strong> Optimized gradient boosting with regularization and second-order split finding.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-16.html">16. LightGBM Regression</a>
          <p><strong>What:</strong> Histogram-based, leaf-wise boosting; very fast on large/high-cardinality data.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-17.html">17. Neural Network Regression (MLP)</a>
          <p><strong>What:</strong> Multi-layer perceptrons trained by backprop; flexible function approximators.</p>
        </div>
      </li>

      <li>
        <span class="chapter-number"></span>
        <div class="chapter-entry">
          <a href="model-18.html">18. K-Nearest Neighbors Regression</a>
          <p><strong>What:</strong> Nonparametric local averaging of neighbor targets (optionally distance-weighted).</p>
        </div>
      </li>
    </ol>
  </section>

  <footer class="site-footer">
    <p>Style unified via <code>styles.css</code>. Each chapter page includes background, math & deduction, an expandable Python example, and a figure.</p>
  </footer>
</main>
</body>
</html>
