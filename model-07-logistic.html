<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>7. Logistic Regression (Binary) — Regression Models Handbook</title>
<link rel="stylesheet" href="styles.css" />

<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['\\[', '\\]'], ['$$','$$']],
    processEscapes: true,
    tags: 'ams'
  },
  options: { skipHtmlTags: ['script','noscript','style','textarea','pre','code'] }
};
</script>
<script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>

</head>
<body>
<main class="book-page">
  <header class="book-header">
    <p class="lead">Regression Models Handbook</p>
    <h1>7. Logistic Regression (Binary)</h1>
  </header>

  
    <nav class="chapter-nav top">
      <a href="model-06-stepwise.html">&larr; Prev</a>
      <a class="index-link" href="index.html">Index</a>
      <a href="model-08-elastic-net.html">Next &rarr;</a>
    </nav>
    

  <section class="card">
    <h2>Overview & Background</h2>
    <p>Logistic regression models a binary outcome via the log-odds (logit) link. Parameters are estimated by maximizing the Bernoulli likelihood.</p>
  </section>

  <section class="card">
    <h2>Mathematics & Derivation</h2>
    <p class="formula">For $y\in\{0,1\}$, $\Pr(y=1\mid x)=\sigma(x^\top\beta)$ with $\sigma(z)=1/(1+e^{-z})$. Log-likelihood: $$\ell(\beta)=\sum_i y_i x_i^\top\beta - \sum_i \log\big(1+e^{x_i^\top\beta}\big).$$ Gradient ascent/Newton methods yield the MLE.</p>
    <p class="muted"></p>
  </section>

  <section class="card">
    <h2>When to Use (Best For)</h2>
    <ul>
      <li>Disease yes/no, response vs non-response</li>
<li>Probability estimation with interpretable odds ratios</li>
<li>Baseline linear classifier</li>
    </ul>
  </section>

  <section class="card">
    <h2>Example & Code</h2>
    <p>Below we simulate data with white noise, fit the model, and create a plot showing original data, fitted values, and residuals. Run this locally (see comments for required packages).</p>
    <details>
      <summary>Show Python example</summary>
      <pre class="ex"><code># Requirements: numpy, matplotlib, scikit-learn (or statsmodels/lifelines as noted).
# This example simulates data with white noise, fits the model, and plots:
#   - original data
#   - fitted curve/predictions
#   - residuals (errors)
import numpy as np
import matplotlib.pyplot as plt
rng = np.random.default_rng(42)

from sklearn.linear_model import LogisticRegression

n = 300
x = rng.uniform(-3, 3, size=(n,1))
beta0, beta1 = -0.5, 1.2
z = beta0 + beta1 * x[:,0] + rng.normal(scale=0.8, size=n)
p = 1/(1+np.exp(-z))
y = (rng.uniform(size=n) &lt; p).astype(int)

model = LogisticRegression().fit(x, y)
x_grid = np.linspace(x.min(), x.max(), 200).reshape(-1,1)
proba_grid = model.predict_proba(x_grid)[:,1]

# For visualization, residuals are less standard; skip residual plot.

plt.figure(figsize=(6,4))
plt.scatter(x, y, s=12, label=&#x27;Class (0/1)&#x27;, c=y, cmap=&#x27;coolwarm&#x27;)
plt.plot(x_grid, proba_grid, linewidth=2, label=&#x27;P(y=1|x)&#x27;)
plt.title(&#x27;Logistic fit&#x27;)
plt.legend()
plt.tight_layout()
plt.savefig(&#x27;assets/07-logistic-regression-binary.png&#x27;, dpi=140)
plt.show()</code></pre>
    </details>
  </section>

  <section class="card">
    <h2>Figure & Interpretation</h2>
    <figure>
      <img src="assets/07-logistic-regression-binary.png" alt="Demo plot for Logistic Regression (Binary) (original data, fitted curve, residuals)" style="width:100%;max-width:100%;" />
      <figcaption>Generated by the example code: Left — original data with fitted curve; Right — residual diagnostics (or probability curve for classifiers).</figcaption>
    </figure>
    <p>The <strong>original data</strong> points are scattered due to added white noise. The <strong>fitted curve</strong> represents model predictions on a dense grid. The <strong>residuals</strong> ($y - \hat y$) highlight model mismatch; patterns may suggest missing features, nonlinearity, or heteroskedasticity.</p>
  </section>

  
    <nav class="chapter-nav bottom">
      <a href="model-06-stepwise.html">&larr; Prev</a>
      <a class="index-link" href="index.html">Index</a>
      <a href="model-08-elastic-net.html">Next &rarr;</a>
    </nav>
    

  <footer class="site-footer">
    <p>&copy; Regression Models Handbook</p>
  </footer>
</main>
</body>
</html>
